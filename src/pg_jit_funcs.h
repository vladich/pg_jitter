/*
 * pg_jit_funcs.h — Unwrapped PG function declarations for direct JIT calls
 *
 * Maps hot PG built-in functions to thin native implementations that bypass
 * the V1 fmgr calling convention (fcinfo). The JIT backends use the lookup
 * table to dispatch direct calls at JIT compile time.
 */
#ifndef PG_JIT_FUNCS_H
#define PG_JIT_FUNCS_H

#include "postgres.h"
#include "fmgr.h"

/*
 * Argument/return type classification for JIT calling convention.
 * Maps to sljit (32 / W), asmjit (int32_t / int64_t), MIR (I32 / I64).
 */
#define JIT_TYPE_32   0   /* 32-bit: int32, uint32, int16, bool */
#define JIT_TYPE_64   1   /* 64-bit: int64, Datum, pointer */

/*
 * Inline operation codes for emit_inline_funcexpr().
 * When set on a JitDirectFn entry, the sljit backend emits the operation
 * as inline instructions instead of calling jit_fn.
 */
typedef enum JitInlineOp
{
	JIT_INLINE_NONE = 0,
	/* int32 arithmetic (overflow-checked) */
	JIT_INLINE_INT4_ADD, JIT_INLINE_INT4_SUB, JIT_INLINE_INT4_MUL,
	JIT_INLINE_INT4_DIV, JIT_INLINE_INT4_MOD,
	/* int64 arithmetic (overflow-checked) */
	JIT_INLINE_INT8_ADD, JIT_INLINE_INT8_SUB, JIT_INLINE_INT8_MUL,
	/* int32 comparison */
	JIT_INLINE_INT4_EQ, JIT_INLINE_INT4_NE,
	JIT_INLINE_INT4_LT, JIT_INLINE_INT4_LE,
	JIT_INLINE_INT4_GT, JIT_INLINE_INT4_GE,
	/* int64 comparison */
	JIT_INLINE_INT8_EQ, JIT_INLINE_INT8_NE,
	JIT_INLINE_INT8_LT, JIT_INLINE_INT8_LE,
	JIT_INLINE_INT8_GT, JIT_INLINE_INT8_GE,
} JitInlineOp;

/*
 * Lookup entry: maps PG fn_addr → direct-call function + metadata.
 * Searched once per expression step at JIT compile time, not per row.
 */
typedef struct JitDirectFn
{
	PGFunction   pg_fn;        /* PG's V1 function address (e.g., int4pl) */
	void        *jit_fn;       /* our unwrapped native version, or NULL */
	uint8        nargs;        /* number of native args (0-4) */
	uint8        ret_type;     /* JIT_TYPE_32 or JIT_TYPE_64 */
	uint8        arg_types[4]; /* type of each arg */
	uint8        inline_op;    /* JitInlineOp, or 0 for none */
	const char  *jit_fn_name;  /* name of jit_fn for precompiled blob lookup */
} JitDirectFn;

extern const JitDirectFn jit_direct_fns[];
extern const int jit_direct_fns_count;

/*
 * Find the direct-call entry for a PG function address.
 * Returns NULL if no direct call is available.
 * Linear scan over ~350 entries — CPU caches it after first lookup.
 */
const JitDirectFn *jit_find_direct_fn(PGFunction pg_fn);

/*
 * Build an sljit call-type bitmask from a JitDirectFn.
 * Encoding: ret_type in bits 0-3, arg[i] type in bits 4*(i+1)..4*(i+1)+3
 * Type values: 1 = W (64-bit), 2 = 32-bit
 */
static inline uint32
jit_sljit_call_type(const JitDirectFn *dfn)
{
	/* Map: JIT_TYPE_32 → 2 (SLJIT 32-bit), JIT_TYPE_64 → 1 (SLJIT W) */
	static const uint32 type_map[] = { 2, 1 };
	uint32 result = type_map[dfn->ret_type];
	for (int i = 0; i < dfn->nargs; i++)
		result |= type_map[dfn->arg_types[i]] << ((i + 1) * 4);
	return result;
}

/*
 * Error handlers — cold path, callable from JIT code.
 * These never return (ereport), so no register save needed at call site.
 */
extern pg_noinline void jit_error_int2_overflow(void);
extern pg_noinline void jit_error_int4_overflow(void);
extern pg_noinline void jit_error_int8_overflow(void);
extern pg_noinline void jit_error_division_by_zero(void);
extern pg_noinline void jit_error_float_overflow(void);
extern pg_noinline void jit_error_float_underflow(void);

/*
 * Pre-compiled inline blob support.
 *
 * When PG_JITTER_HAVE_PRECOMPILED is defined, the sljit backend can emit
 * clang-optimized native code for Tier 1 functions instead of hand-written
 * sljit instruction sequences.
 */
#ifdef PG_JITTER_HAVE_PRECOMPILED
#include "pg_jit_precompiled.h"

/*
 * Find the pre-compiled inline blob for a jit_* function name.
 * Returns NULL if no blob is available.
 */
static inline const PrecompiledInline *
jit_find_precompiled(const char *fn_name)
{
	for (int i = 0; i < precompiled_inlines_count; i++)
	{
		if (strcmp(precompiled_inlines[i].name, fn_name) == 0)
			return precompiled_inlines[i].blob;
	}
	return NULL;
}
#endif /* PG_JITTER_HAVE_PRECOMPILED */

/*
 * Pre-compiled Tier 2 wrapper declarations.
 * These are auto-generated by gen_tier2_wrappers.py and compiled from
 * PG bitcode with LLVM optimizations (function bodies inlined).
 */
#ifdef PG_JITTER_HAVE_TIER2
extern int32 jit_numeric_eq_precompiled(int64 a, int64 b);
extern int32 jit_numeric_ne_precompiled(int64 a, int64 b);
extern int32 jit_numeric_lt_precompiled(int64 a, int64 b);
extern int32 jit_numeric_le_precompiled(int64 a, int64 b);
extern int32 jit_numeric_gt_precompiled(int64 a, int64 b);
extern int32 jit_numeric_ge_precompiled(int64 a, int64 b);
extern int32 jit_numeric_cmp_precompiled(int64 a, int64 b);
extern int64 jit_numeric_add_precompiled(int64 a, int64 b);
extern int64 jit_numeric_sub_precompiled(int64 a, int64 b);
extern int64 jit_numeric_mul_precompiled(int64 a, int64 b);
extern int32 jit_hash_numeric_precompiled(int64 a);
extern int32 jit_texteq_precompiled(int64 a, int64 b);
extern int32 jit_textne_precompiled(int64 a, int64 b);
extern int32 jit_text_lt_precompiled(int64 a, int64 b);
extern int32 jit_bttextcmp_precompiled(int64 a, int64 b);
extern int32 jit_hashtext_precompiled(int64 a);
extern int32 jit_interval_eq_precompiled(int64 a, int64 b);
extern int32 jit_interval_lt_precompiled(int64 a, int64 b);
extern int32 jit_interval_cmp_precompiled(int64 a, int64 b);
extern int32 jit_uuid_eq_precompiled(int64 a, int64 b);
extern int32 jit_uuid_lt_precompiled(int64 a, int64 b);
extern int32 jit_uuid_cmp_precompiled(int64 a, int64 b);
extern int32 jit_uuid_hash_precompiled(int64 a);
#endif /* PG_JITTER_HAVE_TIER2 */

#endif /* PG_JIT_FUNCS_H */
